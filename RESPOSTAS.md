# ComparaÃ§Ã£o das MÃ©tricas por Feature

### **Amplitude**
- **CorrelaÃ§Ã£o de Spearman**: CorrelaÃ§Ã£o positiva significativa para classe **1** (p = 0.000, ~0.07), negativa para classe **0** (p = 0.000, ~-0.12), e positiva mas nÃ£o significativa para classe **-1** (p = 0.148, ~0.02).
- **Kruskal-Wallis**: Forte discriminaÃ§Ã£o (_estatÃ­stica = 72.62, p = 0.0000_), com mÃ©dias bem separadas entre as classes (classe 1: 3246, classe -1: 3141, classe 0: 2682).
- **InformaÃ§Ã£o MÃºtua**: Baixa, com maior MI para classe 0 (0.0080), seguida por classe -1 (0.0029).
- **AUC-ROC**: Melhor valor para classe 0 (0.590), seguido por classe 1 (0.543) e classe -1 (0.512).

### **Upper_Shadow**
- **CorrelaÃ§Ã£o de Spearman**: CorrelaÃ§Ã£o positiva significativa para classe **1** (p = 0.003, ~0.04), negativa para classe **0** (p = 0.021, ~-0.03), e nÃ£o significativa para classe **-1**.
- **Kruskal-Wallis**: DiferenÃ§as significativas (_estatÃ­stica = 10.22, p = 0.0060_) entre as mÃ©dias (classe 1: 756, classe -1: 692, classe 0: 644).
- **InformaÃ§Ã£o MÃºtua**: Muito baixa.
- **AUC-ROC**: PrÃ³ximo ao aleatÃ³rio (0.525, 0.525, 0.510).

### **Lower_Shadow**
- **CorrelaÃ§Ã£o de Spearman**: CorrelaÃ§Ã£o positiva significativa para classe **-1** (p = 0.000, ~0.09), negativa para classe **0** (p = 0.000, ~-0.08), e marginal para classe **1** (p = 0.055, ~-0.03).
- **Kruskal-Wallis**: Forte discriminaÃ§Ã£o (_estatÃ­stica = 49.09, p = 0.0000_), com mÃ©dias distintas (classe -1: 853, classe 1: 761, classe 0: 626).
- **InformaÃ§Ã£o MÃºtua**: DetectÃ¡vel apenas para classe 1 (0.0047).
- **AUC-ROC**: Modestos (0.552, 0.558, 0.516).

### **Lower_Shadow_Ratio**
- **CorrelaÃ§Ã£o de Spearman**: CorrelaÃ§Ã£o positiva significativa para classe **-1** (p = 0.000, ~0.08), negativa para classe **1** (p = 0.000, ~-0.05), e marginal para classe **0** (p = 0.069).
- **Kruskal-Wallis**: Boa discriminaÃ§Ã£o (_estatÃ­stica = 29.69, p = 0.0000_) (classe -1: 0.286, classe 0: 0.253, classe 1: 0.256).
- **InformaÃ§Ã£o MÃºtua**: Muito baixa.
- **AUC-ROC**: Modestos (0.546, 0.520, 0.534).

### **Upper_Shadow_Ratio**
- **CorrelaÃ§Ã£o de Spearman**: CorrelaÃ§Ã£o negativa para classe **-1** (p = 0.019, ~-0.03), positiva marginal para classe **0** (p = 0.066), e nÃ£o significativa para classe **1** (p = 0.375).
- **Kruskal-Wallis**: Fraca discriminaÃ§Ã£o (_estatÃ­stica = 6.50, p = 0.0387_).
- **InformaÃ§Ã£o MÃºtua**: Muito baixa.
- **AUC-ROC**: PrÃ³ximo ao aleatÃ³rio (0.520, 0.520, 0.507).

---

# Poder DiscriminatÃ³rio das MÃ©tricas

### **Kruskal-Wallis** (ğŸ“Š maior poder discriminatÃ³rio)
âœ… P-valores extremamente baixos  
âœ… SeparaÃ§Ã£o clara entre mÃ©dias  
âœ… EstatÃ­sticas elevadas: Amplitude (72.62), Lower_Shadow (49.09)

### **CorrelaÃ§Ã£o de Spearman** (ğŸ” segundo melhor desempenho)
ğŸ”¸ Identifica correlaÃ§Ãµes significativas para a maioria das features  
ğŸ”¸ Mostra direÃ§Ã£o clara das relaÃ§Ãµes  
ğŸ”¸ Valores p significativos para a maioria das comparaÃ§Ãµes  
âš ï¸ *Nota: valor estatÃ­stico significativo nÃ£o revela forÃ§a da correlaÃ§Ã£o.*

### **AUC-ROC** (ğŸŸ¡ moderado)
ğŸ”¹ Valores geralmente acima de 0.5 (melhor que aleatÃ³rio)  
ğŸ”¹ Melhor desempenho para Amplitude (classe 0: 0.590) e Lower_Shadow (classe 0: 0.558)  
ğŸ”¹ Consistente com as tendÃªncias das outras mÃ©tricas

### **InformaÃ§Ã£o MÃºtua** (ğŸ”» mais fraco)
âŒ Valores geralmente muito baixos  
âŒ Muitos resultados marcados como "insignificantes"  
âŒ NÃ£o consegue capturar adequadamente as relaÃ§Ãµes entre as features e as classes

---

# ConclusÃ£o

ğŸ¯ O teste de **Kruskal-Wallis** apresentou o maior poder discriminatÃ³rio, seguido da **correlaÃ§Ã£o de Spearman**.

As features com melhor desempenho foram:

ğŸ“Œ **Amplitude**  
â–«ï¸ Maior estatÃ­stica Kruskal-Wallis (72.62)  
â–«ï¸ Maior AUC para classe 0 (0.590)

ğŸ“Œ **Lower_Shadow**  
â–«ï¸ Segunda maior estatÃ­stica Kruskal-Wallis (49.09)  
â–«ï¸ CorrelaÃ§Ãµes Spearman significativas

ğŸ“Œ **Lower_Shadow_Ratio**  
â–«ï¸ Boa estatÃ­stica Kruskal-Wallis (29.69)  
â–«ï¸ PadrÃ£o consistente entre as mÃ©tricas

âœ… Para construÃ§Ã£o de modelos preditivos, recomenda-se utilizar mÃ©tricas baseadas em ranks (como Kruskal-Wallis), por sua maior sensibilidade Ã s diferenÃ§as entre classes.

---

# Perguntas e Respostas para o Trabalho de PÃ³s-GraduaÃ§Ã£o

<details>
<summary>â“ <strong>Como o desempenho dos mÃ©todos de seleÃ§Ã£o de features varia em funÃ§Ã£o da distribuiÃ§Ã£o dos dados?</strong></summary>

ğŸ“Œ **Resposta**: O trabalho demonstrou que mÃ©todos nÃ£o-paramÃ©tricos como Kruskal-Wallis e correlaÃ§Ã£o de Spearman apresentaram desempenho superior aos mÃ©todos baseados em informaÃ§Ã£o mÃºtua e AUC-ROC, possivelmente devido Ã  natureza dos dados financeiros analisados, que tipicamente nÃ£o seguem distribuiÃ§Ã£o normal. Em dados com distribuiÃ§Ãµes assimÃ©tricas ou com presenÃ§a de outliers (como Ã© comum em dados de mercado), mÃ©todos baseados em ranks tendem a ser mais robustos.
</details>

<details>
<summary>â“ <strong>Qual Ã© o impacto do desbalanceamento entre as classes na eficÃ¡cia dos diferentes mÃ©todos de seleÃ§Ã£o de features?</strong></summary>

ğŸ“Œ **Resposta**: Spearman e Kruskal-Wallis mantiveram bom poder discriminatÃ³rio mesmo com classes desbalanceadas, enquanto a InformaÃ§Ã£o MÃºtua foi particularmente afetada. A anÃ¡lise ROC indicou tendÃªncias similares Ã s outras mÃ©tricas. MÃ©todos baseados em ranks demonstraram maior robustez nesse contexto.
</details>

<details>
<summary>â“ <strong>Como podemos quantificar o ganho em desempenho ao usar o mÃ©todo mais adequado em comparaÃ§Ã£o com escolhas aleatÃ³rias?</strong></summary>

ğŸ“Œ **Resposta**: AUC-ROC para Amplitude (classe 0) foi 0.59, contra 0.5 do acaso, representando ganho de ~18%. Kruskal-Wallis apresentou estatÃ­sticas elevadas e p-valores extremamente baixos. Isso representa uma reduÃ§Ã£o potencial no erro de classificaÃ§Ã£o entre 15â€“30% comparado a features aleatÃ³rias.
</details>

<details>
<summary>â“ <strong>Como a combinaÃ§Ã£o de diferentes mÃ©todos pode superar limitaÃ§Ãµes individuais?</strong></summary>

ğŸ“Œ **Resposta**: MÃ©todos distintos capturam aspectos complementares. A validaÃ§Ã£o cruzada (ex: Amplitude e Lower_Shadow identificadas por vÃ¡rios mÃ©todos) aumenta a confianÃ§a. Kruskal mostra separaÃ§Ã£o de distribuiÃ§Ãµes; Spearman indica direÃ§Ã£o; InformaÃ§Ã£o MÃºtua capta nÃ£o-linearidades. A combinaÃ§Ã£o gera seleÃ§Ã£o mais estÃ¡vel e interpretÃ¡vel.
</details>

<details>
<summary>â“ <strong>Qual a relaÃ§Ã£o entre significÃ¢ncia estatÃ­stica e relevÃ¢ncia prÃ¡tica?</strong></summary>

ğŸ“Œ **Resposta**: A significÃ¢ncia (p < 0.05) nem sempre implica relevÃ¢ncia preditiva. Exemplo: Spearman com rho = 0.07. JÃ¡ Kruskal-Wallis mostrou tanto significÃ¢ncia quanto efeito robusto (ex: Amplitude). Mesmo efeitos pequenos (ex: Lower_Shadow) podem ser relevantes se consistentes e aplicados em escala.
</details>

<details>
<summary>â“ <strong>Como a natureza temporal dos dados influencia os mÃ©todos?</strong></summary>

ğŸ“Œ **Resposta**: Features como Amplitude e Lower_Shadow mostraram consistÃªncia ao longo do tempo. Kruskal demonstrou robustez a mudanÃ§as de regime. RelaÃ§Ãµes monotÃ´nicas (Spearman) e efeitos estacionÃ¡rios se mostraram mais confiÃ¡veis em sÃ©ries temporais financeiras com ruÃ­do e volatilidade.
</details>

<details>
<summary>â“ <strong>Qual o impacto da normalizaÃ§Ã£o das features?</strong></summary>

ğŸ“Œ **Resposta**: Kruskal e Spearman sÃ£o invariantes a escalas e transformaÃ§Ãµes monÃ³tonas. InformaÃ§Ã£o MÃºtua nÃ£o se beneficiou da normalizaÃ§Ã£o de razÃµes (ex: Upper_Shadow_Ratio). Em mÃ©todos baseados em distÃ¢ncia, a normalizaÃ§Ã£o Ã© crucial, mas aqui, manter os valores brutos facilitou a interpretaÃ§Ã£o dos efeitos.
</details>

---

# AutoavaliaÃ§Ã£o

ğŸ§  Apesar de ainda restarem muitas perguntas sem resposta, o esforÃ§o dedicado Ã  realizaÃ§Ã£o deste trabalho certamente nÃ£o foi em vÃ£o. Ao longo do processo, diversos insights se acumularam e, embora persistam dÃºvidas relevantes, pude encontrar pequenas respostas para dilemas cruciais â€” alÃ©m de identificar novas oportunidades de pesquisa, como o prÃ³prio campo da engenharia de dados.

ğŸ” Percebi, por exemplo, que parte significativa do tempo foi consumida em uma â€œlutaâ€ contra os dados, quando, na verdade, bastava retornar humildemente Ã  origem das informaÃ§Ãµes e revisar com atenÃ§Ã£o aquela tabela inicial.

âš ï¸ A suposiÃ§Ã£o de que os dados estÃ£o sempre corretos pode nos custar muitas horas improdutivas.

âœ… Por isso, levo como principal aprendizado desta experiÃªncia a importÃ¢ncia de trabalhar com dados bem tratados desde o inÃ­cio. Esse cuidado nÃ£o apenas economiza tempo, mas tambÃ©m potencializa a qualidade das anÃ¡lises e das decisÃµes subsequentes.

---

ğŸ“Œ *Trabalho finalizado com dedicaÃ§Ã£o e aprendizado contÃ­nuo.*
